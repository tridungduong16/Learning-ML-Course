{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitdeepprobprogcourseconda071e3aac92a944639a759a069eba10f1",
   "display_name": "Python 3.8.3 64-bit ('deep-probprog-course': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import NUTS, MCMC\n",
    "pyro.enable_validation()\n",
    "dist.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_check_data = pd.read_csv('../data/weather_check/weather-check.csv', sep=r',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename keys to make it easier to manipulate\n",
    "weather_check_data = weather_check_data.rename(columns=lambda x: x.strip())\\\n",
    "                  .drop(columns={'RespondentID', 'A specific website or app (please provide the answer)'})\\\n",
    "                  .rename(columns={'Do you typically check a daily weather report?': 'daily_check',\n",
    "                                   'How do you typically check the weather?': 'how_check',\n",
    "                                   ('If you had a smartwatch (like the soon to be released Apple Watch),'\n",
    "                                   + ' how likely or unlikely would you be to check'\n",
    "                                   + ' the weather on that device?'): 'smartwatch',\n",
    "                                   'Age': 'age',\n",
    "                                   'What is your gender?': 'gender',\n",
    "                                   ('How much total combined money did all members of your'\n",
    "                                   + ' HOUSEHOLD earn last year?'): 'earning',\n",
    "                                   'US Region': 'us_region'})\n",
    "weather_check_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove spaces in row values\n",
    "for c in weather_check_data.keys():\n",
    "    weather_check_data[c] = weather_check_data[c].apply(lambda x: x.strip())\n",
    "# Remove empty answers\n",
    "weather_check_data = weather_check_data.drop(weather_check_data[weather_check_data['how_check'] == '-'].index)\n",
    "# Remove rows where age or gender or earning or us_region is missing.\n",
    "# Note: This makes the data biased, but easier for the exercise to handle.\n",
    "# For real life use cases, you need to do imputation, like: \n",
    "# http://pyro.ai/numpyro/bayesian_imputation.html\n",
    "weather_check_data = weather_check_data.drop(weather_check_data[\n",
    "    (weather_check_data['age'] == '-') | (weather_check_data['gender'] == '-') \n",
    "    | (weather_check_data['earning'] == '-') \n",
    "    | (weather_check_data['earning'] == 'Prefer not to answer') \n",
    "    | (weather_check_data['us_region'] == '-')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "how_types = {t: i for i, t in enumerate(sorted(weather_check_data['how_check'].unique()))}\n",
    "print(how_types)\n",
    "smartwatch_types = {t: i for i, t in enumerate(sorted(weather_check_data['smartwatch'].unique()))}\n",
    "print(smartwatch_types)\n",
    "age_types = {t: i for i, t in enumerate(sorted(weather_check_data['age'].unique()))}\n",
    "print(age_types)\n",
    "gender_types = {t: i for i, t in enumerate(sorted(weather_check_data['gender'].unique()))}\n",
    "print(gender_types)\n",
    "earning_types = {t: i for i, t in enumerate(sorted(weather_check_data['earning'].unique(), key=lambda s: ('up' in s, len(s), s)))}\n",
    "print(earning_types)\n",
    "region_types = {t: i for i, t in enumerate(sorted(weather_check_data['us_region'].unique()))}\n",
    "print(region_types)\n",
    "daily_types = {t: i for i, t in enumerate(sorted(weather_check_data['daily_check'].unique()))}\n",
    "print(daily_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(weather_check_data)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data_inp(df):\n",
    "    how = torch.nn.functional.one_hot(torch.from_numpy(df['how_check']\n",
    "                                      .map(how_types).values), len(how_types))\n",
    "    smartwatch = torch.from_numpy(df['smartwatch'].map(smartwatch_types).values)\n",
    "    age = torch.from_numpy(df['age'].map(age_types).values)\n",
    "    gender = torch.from_numpy(df['gender'].map(gender_types).values)\n",
    "    earning = torch.from_numpy(df['earning'].map(earning_types).values)\n",
    "    combined = torch.cat([how, smartwatch.unsqueeze(-1), age.unsqueeze(-1),\n",
    "                          gender.unsqueeze(-1), earning.unsqueeze(-1)], dim=-1).float()\n",
    "    region = torch.from_numpy(df['us_region'].map(region_types).values)\n",
    "    daily_check = torch.from_numpy(df['daily_check'].map(daily_types).values)\n",
    "    return combined, region, daily_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_components = encode_data_inp(weather_check_data)[0].shape[-1]\n",
    "num_regions = len(region_types)\n",
    "print(\"num_components: \", num_components, \" num_regions:\", num_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(covariates, region, response=None):\n",
    "    pass\n",
    "    # TODO make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tX, tr, ty = encode_data_inp(train)\n",
    "kernel = NUTS(model)\n",
    "mcmc = MCMC(kernel, 1000, 100)\n",
    "mcmc.run(tX, tr, ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sX, sr, sy = encode_data_inp(test)\n",
    "samples = mcmc.get_samples(100)\n",
    "res = []\n",
    "for i in range(100):\n",
    "    res.append((torch.sigmoid(sX @ samples['beta'][i] + samples['gamma'][i][sr]) >= 0.5) * 1.)\n",
    "res = torch.stack(res)\n",
    "print((1.*(res == sy)).mean())\n",
    "print((1.*(res == sy)).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}